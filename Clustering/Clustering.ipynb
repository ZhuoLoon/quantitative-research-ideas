{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "sys.path.append(os.getcwd()[:-10])\n",
    "from Filtering.filtering import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, we will be clustering securities in our trading universe.\n",
    "\n",
    "As an example, we will download 6 months of historical stock data for our trading universe, preprocess the data to obtain observation values and perform clustering using a Gaussian Mixture Model.\n",
    "\n",
    "More precisely, the observations are smoothed daily returns obtained using the formulas provided by Zura Kakushadze and Willie Yu\n",
    "    \\begin{align*}\n",
    "    \\\\\n",
    "    &S^i_t := \\text{Security } i \\text{ close price, time } t\\\\\n",
    "    &R^i_t := \\text{Returns of } S^i_t\\\\\n",
    "    &\\sigma^i := \\text {Serial standard deviation of }R^i_t\\\\\n",
    "    &\\tilde{R^i_t} := \\frac{R^i_t}{\\sigma^i}, \\quad \\text{\"Normalised Returns\"}\\\\\n",
    "    &\\hat{R^i_i} := \\frac{\\tilde{R^i_t}}{u_i}, \\quad \\text{\"Smoothed Returns\"}\\\\\n",
    "    &u_i := \\max(\n",
    "                 \\exp(\n",
    "                      \\log(\\sigma_i) - (\n",
    "                          \\text{Median}(\\log(\\sigma_i)) - 3 * \\text{Mean Absolute Deviation}(\\log(\\sigma_i))\n",
    "                                       )\n",
    "                      )\n",
    "    , 1)\\\\\\\\\n",
    "    &\\text{Median(·) and MAD(·) above are cross-sectional.}\n",
    "    \\end{align*}\n",
    "\n",
    "References:\n",
    "- Z. Kakushadze, W. Yu. Statistical Industry Classification. arXiv:1607.04883\n",
    "\n",
    "\n",
    "### Filtering Trading Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  422 of 422 completed\n",
      "['GOOGL', 'GOOG', 'AMZN', 'AAPL', 'BA', 'FB', 'MU', 'MSFT', 'NFLX', 'NVDA', 'V', 'DIS']\n"
     ]
    }
   ],
   "source": [
    "listed_companies = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\")[0].set_index('Symbol')\n",
    "\n",
    "# pd.to_datetime cannot be called directly due to inconsistent data structures\n",
    "def try_mapping_to_datetime(date):\n",
    "    try:\n",
    "        return pd.Timestamp(date)\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "# Removing companies listed after 2020/01/01\n",
    "listed_companies['Date first added'] = listed_companies['Date first added'].map(try_mapping_to_datetime)\n",
    "listed_companies = listed_companies.dropna()\n",
    "listed_companies = listed_companies[listed_companies['Date first added'] < pd.Timestamp('2020-01-01')]\n",
    "\n",
    "# Filtering\n",
    "trading_universe = filter_universe(securities = listed_companies.index.to_list(),\n",
    "                                   current_time = pd.Timestamp('2020-01-01'),\n",
    "                                   lookback=30,\n",
    "                                   percentile=.05)\n",
    "\n",
    "print(trading_universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  12 of 12 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>BA</th>\n",
       "      <th>DIS</th>\n",
       "      <th>FB</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>MU</th>\n",
       "      <th>NFLX</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-01</th>\n",
       "      <td>49.459972</td>\n",
       "      <td>1922.189941</td>\n",
       "      <td>350.111084</td>\n",
       "      <td>139.939774</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>1097.949951</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>132.745392</td>\n",
       "      <td>40.011353</td>\n",
       "      <td>374.600006</td>\n",
       "      <td>41.378731</td>\n",
       "      <td>171.285995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-02</th>\n",
       "      <td>49.749546</td>\n",
       "      <td>1934.310059</td>\n",
       "      <td>347.852051</td>\n",
       "      <td>140.809143</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>1111.250000</td>\n",
       "      <td>1112.599976</td>\n",
       "      <td>133.625900</td>\n",
       "      <td>39.502602</td>\n",
       "      <td>375.429993</td>\n",
       "      <td>40.397610</td>\n",
       "      <td>172.605560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-03</th>\n",
       "      <td>50.161819</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>348.156494</td>\n",
       "      <td>141.253708</td>\n",
       "      <td>197.199997</td>\n",
       "      <td>1121.579956</td>\n",
       "      <td>1122.989990</td>\n",
       "      <td>134.486893</td>\n",
       "      <td>39.492630</td>\n",
       "      <td>381.720001</td>\n",
       "      <td>40.527100</td>\n",
       "      <td>174.171265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-05</th>\n",
       "      <td>50.117641</td>\n",
       "      <td>1942.910034</td>\n",
       "      <td>349.521729</td>\n",
       "      <td>141.601624</td>\n",
       "      <td>196.399994</td>\n",
       "      <td>1131.589966</td>\n",
       "      <td>1132.670044</td>\n",
       "      <td>134.095535</td>\n",
       "      <td>39.323044</td>\n",
       "      <td>380.549988</td>\n",
       "      <td>39.899586</td>\n",
       "      <td>173.964493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-08</th>\n",
       "      <td>49.084515</td>\n",
       "      <td>1952.319946</td>\n",
       "      <td>344.866180</td>\n",
       "      <td>140.180145</td>\n",
       "      <td>195.759995</td>\n",
       "      <td>1116.349976</td>\n",
       "      <td>1116.790039</td>\n",
       "      <td>133.997711</td>\n",
       "      <td>40.310612</td>\n",
       "      <td>376.160004</td>\n",
       "      <td>39.147560</td>\n",
       "      <td>173.501648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AAPL         AMZN          BA         DIS          FB  \\\n",
       "Date                                                                     \n",
       "2019-07-01  49.459972  1922.189941  350.111084  139.939774  193.000000   \n",
       "2019-07-02  49.749546  1934.310059  347.852051  140.809143  195.000000   \n",
       "2019-07-03  50.161819  1939.000000  348.156494  141.253708  197.199997   \n",
       "2019-07-05  50.117641  1942.910034  349.521729  141.601624  196.399994   \n",
       "2019-07-08  49.084515  1952.319946  344.866180  140.180145  195.759995   \n",
       "\n",
       "                   GOOG        GOOGL        MSFT         MU        NFLX  \\\n",
       "Date                                                                      \n",
       "2019-07-01  1097.949951  1100.000000  132.745392  40.011353  374.600006   \n",
       "2019-07-02  1111.250000  1112.599976  133.625900  39.502602  375.429993   \n",
       "2019-07-03  1121.579956  1122.989990  134.486893  39.492630  381.720001   \n",
       "2019-07-05  1131.589966  1132.670044  134.095535  39.323044  380.549988   \n",
       "2019-07-08  1116.349976  1116.790039  133.997711  40.310612  376.160004   \n",
       "\n",
       "                 NVDA           V  \n",
       "Date                               \n",
       "2019-07-01  41.378731  171.285995  \n",
       "2019-07-02  40.397610  172.605560  \n",
       "2019-07-03  40.527100  174.171265  \n",
       "2019-07-05  39.899586  173.964493  \n",
       "2019-07-08  39.147560  173.501648  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bar_data = yf.download(tickers=trading_universe,\n",
    "                             start='2019-07-01',\n",
    "                             end='2020-01-01')['Adj Close']\n",
    "\n",
    "daily_bar_data = daily_bar_data.dropna(axis=1)\n",
    "daily_bar_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating observation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate returns\n",
    "returns = daily_bar_data.pct_change()\n",
    "returns = returns.dropna()\n",
    "\n",
    "# normalising returns\n",
    "standard_deviation = returns.std(axis=0)\n",
    "normalised_returns = returns / standard_deviation\n",
    "\n",
    "# smoothing_returns\n",
    "log_standard_deviation = np.log(standard_deviation)\n",
    "smoothing_factor = log_standard_deviation - (log_standard_deviation.median() - 3 * log_standard_deviation.mad())\n",
    "smoothing_factor = np.exp(smoothing_factor)\n",
    "smoothing_factor[smoothing_factor < 1] = 1\n",
    "smoothed_returns = normalised_returns / smoothing_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>BA</th>\n",
       "      <th>DIS</th>\n",
       "      <th>FB</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>MU</th>\n",
       "      <th>NFLX</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-02</th>\n",
       "      <td>0.213180</td>\n",
       "      <td>0.346405</td>\n",
       "      <td>-0.154417</td>\n",
       "      <td>0.243913</td>\n",
       "      <td>0.375291</td>\n",
       "      <td>0.431239</td>\n",
       "      <td>0.438858</td>\n",
       "      <td>0.395792</td>\n",
       "      <td>-0.152619</td>\n",
       "      <td>0.035802</td>\n",
       "      <td>-0.342279</td>\n",
       "      <td>0.401878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-03</th>\n",
       "      <td>0.301743</td>\n",
       "      <td>0.133203</td>\n",
       "      <td>0.020946</td>\n",
       "      <td>0.123959</td>\n",
       "      <td>0.408585</td>\n",
       "      <td>0.330928</td>\n",
       "      <td>0.357787</td>\n",
       "      <td>0.384470</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>0.270724</td>\n",
       "      <td>0.046272</td>\n",
       "      <td>0.473196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-05</th>\n",
       "      <td>-0.032068</td>\n",
       "      <td>0.110784</td>\n",
       "      <td>0.093845</td>\n",
       "      <td>0.096704</td>\n",
       "      <td>-0.146920</td>\n",
       "      <td>0.317725</td>\n",
       "      <td>0.330255</td>\n",
       "      <td>-0.173639</td>\n",
       "      <td>-0.051542</td>\n",
       "      <td>-0.049528</td>\n",
       "      <td>-0.223518</td>\n",
       "      <td>-0.061930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-08</th>\n",
       "      <td>-0.750591</td>\n",
       "      <td>0.266076</td>\n",
       "      <td>-0.318769</td>\n",
       "      <td>-0.394134</td>\n",
       "      <td>-0.118014</td>\n",
       "      <td>-0.479449</td>\n",
       "      <td>-0.537149</td>\n",
       "      <td>-0.043530</td>\n",
       "      <td>0.301445</td>\n",
       "      <td>-0.186404</td>\n",
       "      <td>-0.272082</td>\n",
       "      <td>-0.138791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-09</th>\n",
       "      <td>0.222094</td>\n",
       "      <td>1.012476</td>\n",
       "      <td>0.134275</td>\n",
       "      <td>0.164265</td>\n",
       "      <td>0.638252</td>\n",
       "      <td>0.270422</td>\n",
       "      <td>0.257298</td>\n",
       "      <td>-0.217841</td>\n",
       "      <td>0.279207</td>\n",
       "      <td>0.161947</td>\n",
       "      <td>0.009183</td>\n",
       "      <td>0.455961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AAPL      AMZN        BA       DIS        FB      GOOG  \\\n",
       "Date                                                                     \n",
       "2019-07-02  0.213180  0.346405 -0.154417  0.243913  0.375291  0.431239   \n",
       "2019-07-03  0.301743  0.133203  0.020946  0.123959  0.408585  0.330928   \n",
       "2019-07-05 -0.032068  0.110784  0.093845  0.096704 -0.146920  0.317725   \n",
       "2019-07-08 -0.750591  0.266076 -0.318769 -0.394134 -0.118014 -0.479449   \n",
       "2019-07-09  0.222094  1.012476  0.134275  0.164265  0.638252  0.270422   \n",
       "\n",
       "               GOOGL      MSFT        MU      NFLX      NVDA         V  \n",
       "Date                                                                    \n",
       "2019-07-02  0.438858  0.395792 -0.152619  0.035802 -0.342279  0.401878  \n",
       "2019-07-03  0.357787  0.384470 -0.003030  0.270724  0.046272  0.473196  \n",
       "2019-07-05  0.330255 -0.173639 -0.051542 -0.049528 -0.223518 -0.061930  \n",
       "2019-07-08 -0.537149 -0.043530  0.301445 -0.186404 -0.272082 -0.138791  \n",
       "2019-07-09  0.257298 -0.217841  0.279207  0.161947  0.009183  0.455961  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothed_returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "securities = smoothed_returns.columns\n",
    "clustering_model = GaussianMixture(n_components=8).fit(smoothed_returns.values.T)\n",
    "cluster_tags = clustering_model.predict(smoothed_returns.values.T)\n",
    "\n",
    "clusters_of_securities = defaultdict(list)\n",
    "for i in range(smoothed_returns.shape[1]):\n",
    "    clusters_of_securities[cluster_tags[i]].append(securities[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {7: ['AAPL'],\n",
       "             4: ['AMZN'],\n",
       "             5: ['BA'],\n",
       "             3: ['DIS'],\n",
       "             6: ['FB'],\n",
       "             0: ['GOOG', 'GOOGL'],\n",
       "             2: ['MSFT', 'V'],\n",
       "             1: ['MU', 'NFLX', 'NVDA']})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_of_securities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements\n",
    "\n",
    "Clustering is a complex task. The algorithm presented here is overly simplistic and hence there are many areas of improvements. Some questions to consider are:\n",
    "\n",
    "- Optimal clustering length: Securities rarely exhibit highly correlated behaviours over long periods of time (6 months in this case). On the other hand, choosing a period that is too short leads to spurious results.\n",
    "- Number of clusters: Getting this number algorithmically rather than discretionally setting it apriori\n",
    "- Randomness of clustering algorithms: How to ensure consistent performance\n",
    "- Clustering algorithm: Hierarchical clustering VS Gaussian Mixture Models\n",
    "- ONC algorithm suggested by López de Prado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
