{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "sys.path.append(os.getcwd()[:-10])\n",
    "from Filtering.filtering import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, we will be clustering securities in our trading universe.\n",
    "\n",
    "As an example, we will download 6 months of historical stock data for our trading universe, preprocess the data to obtain observation values and perform clustering using a Gaussian Mixture Model.\n",
    "\n",
    "More precisely, the observations are smoothed daily returns obtained using the formulas provided by Zura Kakushadze and Willie Yu\n",
    "    \\begin{align*}\n",
    "    \\\\\n",
    "    &S^i_t := \\text{Security } i \\text{ close price, time } t\\\\\n",
    "    &R^i_t := \\text{Returns of } S^i_t\\\\\n",
    "    &\\sigma^i := \\text {Serial standard deviation of }R^i_t\\\\\n",
    "    &\\tilde{R^i_t} := \\frac{R^i_t}{\\sigma^i}, \\quad \\text{\"Normalised Returns\"}\\\\\n",
    "    &\\hat{R^i_i} := \\frac{\\tilde{R^i_t}}{u_i}, \\quad \\text{\"Smoothed Returns\"}\\\\\n",
    "    &u_i := \\max(\n",
    "                 \\exp(\n",
    "                      \\log(\\sigma_i) - (\n",
    "                          \\text{Median}(\\log(\\sigma_i)) - 3 * \\text{Mean Absolute Deviation}(\\log(\\sigma_i))\n",
    "                                       )\n",
    "                      )\n",
    "    , 1)\\\\\\\\\n",
    "    &\\text{Median(·) and MAD(·) above are cross-sectional.}\n",
    "    \\end{align*}\n",
    "\n",
    "References:\n",
    "- Z. Kakushadze, W. Yu. Statistical Industry Classification. arXiv:1607.04883\n",
    "\n",
    "\n",
    "### Filtering Trading Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  256 of 256 completed\n",
      "['GOOG', 'AMZN', 'AAPL', 'BAC', 'C', 'CMCSA', 'GS', 'MSFT', 'ORCL', 'UNH', 'V']\n"
     ]
    }
   ],
   "source": [
    "listed_companies = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\")[0].set_index('Symbol')\n",
    "\n",
    "# pd.to_datetime cannot be called directly due to inconsistent data structures\n",
    "def try_mapping_to_datetime(date):\n",
    "    try:\n",
    "        return pd.Timestamp(date)\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "# Removing companies listed after 2010/01/01\n",
    "listed_companies['Date first added'] = listed_companies['Date first added'].map(try_mapping_to_datetime)\n",
    "listed_companies = listed_companies.dropna()\n",
    "listed_companies = listed_companies[listed_companies['Date first added'] < pd.Timestamp('2010-01-01')]\n",
    "\n",
    "# Filtering\n",
    "trading_universe = filter_universe(securities = listed_companies.index.to_list(),\n",
    "                                   current_time = pd.Timestamp('2010-01-01'),\n",
    "                                   lookback=30,\n",
    "                                   percentile=.1)\n",
    "\n",
    "print(trading_universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  11 of 11 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>BAC</th>\n",
       "      <th>C</th>\n",
       "      <th>CMCSA</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>GS</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>ORCL</th>\n",
       "      <th>UNH</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-01</th>\n",
       "      <td>49.314014</td>\n",
       "      <td>1922.189941</td>\n",
       "      <td>27.774740</td>\n",
       "      <td>65.024223</td>\n",
       "      <td>40.442707</td>\n",
       "      <td>1097.949951</td>\n",
       "      <td>196.166092</td>\n",
       "      <td>132.249786</td>\n",
       "      <td>55.461327</td>\n",
       "      <td>233.399399</td>\n",
       "      <td>171.285980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-02</th>\n",
       "      <td>49.602726</td>\n",
       "      <td>1934.310059</td>\n",
       "      <td>27.519838</td>\n",
       "      <td>64.748459</td>\n",
       "      <td>40.813831</td>\n",
       "      <td>1111.250000</td>\n",
       "      <td>195.331589</td>\n",
       "      <td>133.127045</td>\n",
       "      <td>55.891560</td>\n",
       "      <td>234.678757</td>\n",
       "      <td>172.605530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-03</th>\n",
       "      <td>50.013779</td>\n",
       "      <td>1939.000000</td>\n",
       "      <td>27.425430</td>\n",
       "      <td>65.125328</td>\n",
       "      <td>41.223022</td>\n",
       "      <td>1121.579956</td>\n",
       "      <td>195.388474</td>\n",
       "      <td>133.984802</td>\n",
       "      <td>56.273987</td>\n",
       "      <td>235.871552</td>\n",
       "      <td>174.171280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-05</th>\n",
       "      <td>49.969738</td>\n",
       "      <td>1942.910034</td>\n",
       "      <td>27.623688</td>\n",
       "      <td>65.630882</td>\n",
       "      <td>41.184952</td>\n",
       "      <td>1131.589966</td>\n",
       "      <td>197.152283</td>\n",
       "      <td>133.594910</td>\n",
       "      <td>56.675526</td>\n",
       "      <td>237.583755</td>\n",
       "      <td>173.964478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-08</th>\n",
       "      <td>48.939671</td>\n",
       "      <td>1952.319946</td>\n",
       "      <td>27.567043</td>\n",
       "      <td>65.382706</td>\n",
       "      <td>40.566422</td>\n",
       "      <td>1116.349976</td>\n",
       "      <td>195.113464</td>\n",
       "      <td>133.497437</td>\n",
       "      <td>56.914539</td>\n",
       "      <td>238.401352</td>\n",
       "      <td>173.501694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AAPL         AMZN        BAC          C      CMCSA  \\\n",
       "Date                                                                  \n",
       "2019-07-01  49.314014  1922.189941  27.774740  65.024223  40.442707   \n",
       "2019-07-02  49.602726  1934.310059  27.519838  64.748459  40.813831   \n",
       "2019-07-03  50.013779  1939.000000  27.425430  65.125328  41.223022   \n",
       "2019-07-05  49.969738  1942.910034  27.623688  65.630882  41.184952   \n",
       "2019-07-08  48.939671  1952.319946  27.567043  65.382706  40.566422   \n",
       "\n",
       "                   GOOG          GS        MSFT       ORCL         UNH  \\\n",
       "Date                                                                     \n",
       "2019-07-01  1097.949951  196.166092  132.249786  55.461327  233.399399   \n",
       "2019-07-02  1111.250000  195.331589  133.127045  55.891560  234.678757   \n",
       "2019-07-03  1121.579956  195.388474  133.984802  56.273987  235.871552   \n",
       "2019-07-05  1131.589966  197.152283  133.594910  56.675526  237.583755   \n",
       "2019-07-08  1116.349976  195.113464  133.497437  56.914539  238.401352   \n",
       "\n",
       "                     V  \n",
       "Date                    \n",
       "2019-07-01  171.285980  \n",
       "2019-07-02  172.605530  \n",
       "2019-07-03  174.171280  \n",
       "2019-07-05  173.964478  \n",
       "2019-07-08  173.501694  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bar_data = yf.download(tickers=trading_universe,\n",
    "                             start='2009-07-01',\n",
    "                             end='2010-01-01')['Adj Close']\n",
    "\n",
    "daily_bar_data = daily_bar_data.dropna(axis=1)\n",
    "daily_bar_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating observation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate returns\n",
    "returns = daily_bar_data.pct_change()\n",
    "returns = returns.dropna()\n",
    "\n",
    "# normalising returns\n",
    "standard_deviation = returns.std(axis=0)\n",
    "normalised_returns = returns / standard_deviation\n",
    "\n",
    "# smoothing_returns\n",
    "log_standard_deviation = np.log(standard_deviation)\n",
    "smoothing_factor = log_standard_deviation - (log_standard_deviation.median() - 3 * log_standard_deviation.mad())\n",
    "smoothing_factor = np.exp(smoothing_factor)\n",
    "smoothing_factor[smoothing_factor < 1] = 1\n",
    "smoothed_returns = normalised_returns / smoothing_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>BAC</th>\n",
       "      <th>C</th>\n",
       "      <th>CMCSA</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>GS</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>ORCL</th>\n",
       "      <th>UNH</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-02</th>\n",
       "      <td>0.292820</td>\n",
       "      <td>0.475828</td>\n",
       "      <td>-0.478822</td>\n",
       "      <td>-0.193002</td>\n",
       "      <td>0.646718</td>\n",
       "      <td>0.592358</td>\n",
       "      <td>-0.227474</td>\n",
       "      <td>0.543693</td>\n",
       "      <td>0.523850</td>\n",
       "      <td>0.231287</td>\n",
       "      <td>0.552022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-03</th>\n",
       "      <td>0.414475</td>\n",
       "      <td>0.182971</td>\n",
       "      <td>-0.178984</td>\n",
       "      <td>0.264886</td>\n",
       "      <td>0.706570</td>\n",
       "      <td>0.454569</td>\n",
       "      <td>0.015572</td>\n",
       "      <td>0.528104</td>\n",
       "      <td>0.462057</td>\n",
       "      <td>0.214462</td>\n",
       "      <td>0.650010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-05</th>\n",
       "      <td>-0.044042</td>\n",
       "      <td>0.152175</td>\n",
       "      <td>0.377161</td>\n",
       "      <td>0.353277</td>\n",
       "      <td>-0.065086</td>\n",
       "      <td>0.436433</td>\n",
       "      <td>0.482704</td>\n",
       "      <td>-0.238512</td>\n",
       "      <td>0.481851</td>\n",
       "      <td>0.306294</td>\n",
       "      <td>-0.085081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-08</th>\n",
       "      <td>-1.031015</td>\n",
       "      <td>0.365488</td>\n",
       "      <td>-0.106986</td>\n",
       "      <td>-0.172088</td>\n",
       "      <td>-1.058421</td>\n",
       "      <td>-0.658581</td>\n",
       "      <td>-0.552974</td>\n",
       "      <td>-0.059802</td>\n",
       "      <td>0.284787</td>\n",
       "      <td>0.145205</td>\n",
       "      <td>-0.190621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-09</th>\n",
       "      <td>0.305052</td>\n",
       "      <td>1.390757</td>\n",
       "      <td>0.268011</td>\n",
       "      <td>0.275109</td>\n",
       "      <td>0.578607</td>\n",
       "      <td>0.371457</td>\n",
       "      <td>0.524968</td>\n",
       "      <td>-0.299229</td>\n",
       "      <td>0.079412</td>\n",
       "      <td>-0.313252</td>\n",
       "      <td>0.626291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AAPL      AMZN       BAC         C     CMCSA      GOOG  \\\n",
       "Date                                                                     \n",
       "2019-07-02  0.292820  0.475828 -0.478822 -0.193002  0.646718  0.592358   \n",
       "2019-07-03  0.414475  0.182971 -0.178984  0.264886  0.706570  0.454569   \n",
       "2019-07-05 -0.044042  0.152175  0.377161  0.353277 -0.065086  0.436433   \n",
       "2019-07-08 -1.031015  0.365488 -0.106986 -0.172088 -1.058421 -0.658581   \n",
       "2019-07-09  0.305052  1.390757  0.268011  0.275109  0.578607  0.371457   \n",
       "\n",
       "                  GS      MSFT      ORCL       UNH         V  \n",
       "Date                                                          \n",
       "2019-07-02 -0.227474  0.543693  0.523850  0.231287  0.552022  \n",
       "2019-07-03  0.015572  0.528104  0.462057  0.214462  0.650010  \n",
       "2019-07-05  0.482704 -0.238512  0.481851  0.306294 -0.085081  \n",
       "2019-07-08 -0.552974 -0.059802  0.284787  0.145205 -0.190621  \n",
       "2019-07-09  0.524968 -0.299229  0.079412 -0.313252  0.626291  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothed_returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "securities = smoothed_returns.columns\n",
    "clustering_model = GaussianMixture(n_components=5).fit(smoothed_returns.values.T)\n",
    "cluster_tags = clustering_model.predict(smoothed_returns.values.T)\n",
    "\n",
    "clusters_of_securities = defaultdict(list)\n",
    "for i in range(smoothed_returns.shape[1]):\n",
    "    clusters_of_securities[cluster_tags[i]].append(securities[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {3: ['AAPL', 'GOOG'],\n",
       "             0: ['AMZN', 'MSFT', 'V'],\n",
       "             1: ['BAC', 'C', 'GS', 'ORCL'],\n",
       "             2: ['CMCSA'],\n",
       "             4: ['UNH']})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_of_securities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements\n",
    "\n",
    "Clustering is a complex task. The algorithm presented here is overly simplistic and hence there are many areas of improvements. Some questions to consider are:\n",
    "\n",
    "- Optimal clustering length: Securities rarely exhibit highly correlated behaviours over long periods of time (6 months in this case). On the other hand, choosing a period that is too short leads to spurious results.\n",
    "- Number of clusters: Getting this number algorithmically rather than discretionally setting it apriori\n",
    "- Randomness of clustering algorithms: How to ensure consistent performance\n",
    "- Clustering algorithm: Hierarchical clustering VS Gaussian Mixture Models\n",
    "- ONC algorithm suggested by López de Prado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
